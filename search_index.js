var documenterSearchIndex = {"docs":
[{"location":"log_posterior_background/#Background:-Logarithmic-posterior-probability","page":"Background","title":"Background: Logarithmic posterior probability","text":"","category":"section"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"The general setting is the same as in Background: Posterior probability. The starting point is","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"p(lambda mid x_i_i=1^N y_i_i=1^N m) propto  p_0(lambdamid x_i_i=1^N m) prod_i=1^n ell_i(y_imid lambda x_im) ","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"assuming the likelihoods ell_i are known.","category":"page"},{"location":"log_posterior_background/#Product-of-small-numbers","page":"Background","title":"Product of small numbers","text":"","category":"section"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"In the formula for the posterior likelihood, it can happen that many small numbers (close to zero) need to be multiplied together. Because floating point numbers can only represent numbers up to a certain precision, such products, though theoretically non-zero, tend to be rounded to zero.","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"For example, consider the following array as the likelihood values:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"using Distributions, BenchmarkTools\nsmall_values = [pdf(Normal(0,1),10+i) for i in 1:10]","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"Although the values are non-zero, the product is rounded to zero:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"prod(small_values)","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"One could use floating point types with higher precision:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"small_values_high_precision = BigFloat.(small_values)\nprod(small_values_high_precision)","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"However, this means a huge performance loss together with increased memory usage: ","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"@benchmark prod(small_values)","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"@benchmark prod(small_values_high_precision)","category":"page"},{"location":"log_posterior_background/#Logarithmic-scale","page":"Background","title":"Logarithmic scale","text":"","category":"section"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"Since posterior probabilities are often unnormalized, one is not interested in the particular values, but only in relative differences. But then, any strictly monotonically increasing function can be applied to compare relative differences. A convenient choice for such a strictly monotonically increasing function is the  natural logarithm.","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"Note that because of proportionality, there is a constant alpha  0 such that","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"p(lambda mid x_i_i=1^N y_i_i=1^N m) =  alpha cdot  p_0(lambdamid x_i_i=1^N m) prod_i=1^n ell_i(y_imid lambda x_im) ","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"Applying the natural logarithm leads to:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"beginaligned\nln (p(lambda mid x_i_i=1^N y_i_i=1^N m)) =  ln left(alpha cdot  p_0(lambdamid x_i_i=1^N m) prod_i=1^n ell_i(y_imid lambda x_im) right)  \n= ln(p_0(lambdamid x_i_i=1^N m)) + sum_i=1^N ln(ell_i(y_imid lambda x_im)) + ln(alpha)\nendaligned","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"Using the logarithm allowed to exchange the multiplication of small numbers for an addition in the logarithmic scale, at the cost of having to calculate the logarithm of every value. However, the cost of calculating the logarithm is the worst case scenario. In many cases, it is possible if not easier to implement the logarithm of the involved densities (e.g. for the normal distribution, Laplace distribution, etc.).","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"To shorten the notation, we write L_p = ln circ p for the posterior, L_i= ln circ ell_i for the likelihoods and L_0 =ln circ p_0 for the prior. Then the log-posterior reads ","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"L_p(lambda mid x_i_i=1^N y_i_i=1^N m) =   L_0(lambdamid x_i_i=1^N m) +  sum_i_1^n L_i(y_imid lambda x_im) + textconst","category":"page"},{"location":"log_posterior_background/#Effect-of-the-logarithmic-scale","page":"Background","title":"Effect of the logarithmic scale","text":"","category":"section"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"Using the logarithm has two effects. First of all, the product becomes a sum. This alone would suffice to prevent the rounding to zero problem:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"sum(small_values)","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"In addition, the logarithm has the effect of compressing the number scale for numbers larger than 1 and to stretch out the number scale for numbers between 0 and 1:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"log_values = log.(small_values)","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"Of course, the sum is still non-zero:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"sum(log_values)","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"While the use of higher precision floating point numbers (BigFloat) lead to a huge performance loss, the log scale method dose not impair performance:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"@benchmark sum(log_values)","category":"page"},{"location":"log_posterior_background/#Logarithmic-densities-and-Distributions.jl","page":"Background","title":"Logarithmic densities and Distributions.jl","text":"","category":"section"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"As mentioned in  Logarithmic scale it can be easier to implement some density functions in a logarithmic scale. This is not only true for the implementations from scratch, but also for Distributions.jl. Observe that \"far\" away from the mean, the pdf of a normal distribution is rounded to zero:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"pdf(Normal(0,1),100)","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"Obviously, the logarithm cannot be applied to this. However, Distributions.jl offers a logpdf function:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"logpdf(Normal(0,1),100)","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"This allows values even further away from the mean:","category":"page"},{"location":"log_posterior_background/","page":"Background","title":"Background","text":"logpdf(Normal(0,1),10^20)","category":"page"},{"location":"log_posterior_implementation/#Logarithmic-posterior-probability:-How-to-implement","page":"How to implement","title":"Logarithmic posterior probability: How to implement","text":"","category":"section"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"Consider the data and model from Simple example:","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"using FittingObjectiveFunctions, Plots #hide\n\nX = collect(1:10)\nY = [1.0, 1.78, 3.64, 3.72, 5.33, 2.73, 7.52, 9.19, 6.73, 8.95]\nΔY = [0.38, 0.86, 0.29, 0.45, 0.66, 2.46, 0.39, 0.45, 1.62, 1.54]\nmodel = ModelFunctions((x,λ)-> λ*x)\n\nnothing #hide","category":"page"},{"location":"log_posterior_implementation/#Log-likelihood-and-log-posterior","page":"How to implement","title":"Log-likelihood and log-posterior","text":"","category":"section"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"The general procedure to obtain the log-likelihood and log-posterior functions is the same as described in Posterior probability: How to implement. However, the distributions and the prior need to be in logarithmic form. Thus, the default distributions of the FittingData constructor do not work. Instead, a FittingData object with logarithmic distributions needs to be created:","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"using Distributions\ndata_log_dists = FittingData(X,Y,ΔY,distributions = (y,m,Δy)-> logpdf(Normal(m,Δy),y))\nnothing #hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"The log-likelihood function can be obtained by using the log_posterior_objective function:","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"log_likelihood = log_posterior_objective(data_log_dists,model)\nnothing #hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"As described in Using priors, the likelihood is obtained by using the prior λ-> 1 (or in the logarithmic case λ-> 0). Again, this is what happens in the background. To use a prior, it just needs to be passed as third argument:","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"log_posterior = log_posterior_objective(data_log_dists,model, λ-> logpdf(Normal(1,0.1),λ))\nnothing #hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"The resulting functions can be compared by adjusting the constant offset (see Logarithmic scale)","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"large_scope = plot(x-> log_likelihood(x) + 1.105, xlims = [0.9,1.2], label = \"log_likelihood\", legend = :topleft) #hide\nplot!(log_posterior, label = \"log_posterior\")  #hide\nsmall_scope = plot(x-> log_likelihood(x) + 1.105, xlims = [1.065,1.085], legend = :none) #hide\nplot!(log_posterior)  #hide\nplot(large_scope,small_scope, layout = (1,2), size = (800,300)) #hide","category":"page"},{"location":"log_posterior_implementation/#Application:-Regularized-least-squares","page":"How to implement","title":"Application: Regularized least squares","text":"","category":"section"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"Consider the weighted least squares objective from LSQ:-How-to-implement","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"lsq = lsq_objective(data_log_dists, model)\nnothing #hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"Note that the distributions field of data_log_dists has no effect on least squares objectives. ","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"To replicate the least squares objective, unnormalized logarithmic normal distributions can be used:","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"data_lsq_dists = FittingData(X,Y,ΔY, distributions = (y,m,Δy)-> -(y-m)^2/Δy^2)\nlsq_likelihood = log_posterior_objective(data_lsq_dists,model)\nnothing #hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"plot(lsq, label = \"lsq\") #hide\nplot!(lsq_likelihood, label = \"lsq_likelihood\") #hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"The lsq_likelihood is the same function as lsq, but with the opposite sign (because it is a logarithmic unnormalized posterior probability density). This can be fixed by using λ -> -lsq_likelihood(λ).","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"Now, a regularization can be implemented by using a corresponding logarithmic prior:","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"lsq_posterior = log_posterior_objective(data_lsq_dists,model, λ -> - λ^2)\nnothing #hide","category":"page"},{"location":"log_posterior_implementation/#Partial-derivatives-and-gradients","page":"How to implement","title":"Partial derivatives and gradients","text":"","category":"section"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"Analytical derivatives can be obtained almost in the same way as for the least squares objective derivatives with log_posterior_partials and log_posterior_gradient. However, two additional arguments need to be provided: the partial derivatives of the logarithmic y-uncertainty distributions and the gradient of the prior distribution. ","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"To illustrate the process, we consider a normal distribution as logarithmic y-uncertainty distribution. ","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"data = FittingData(X,Y,ΔY,distributions = (y,m,Δy)-> -(m-y)^2/(2Δy^2))\nnothing # hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"As for the least squares objective derivatives, the partial derivatives of the model need to be added to the  ModelFunctions object:","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"model = ModelFunctions((x,λ)-> λ*x, partials = [(x,λ)-> x])\nnothing # hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"The partial derivative of the logarithmic y-uncertainty distribution (w.r.t. the model function value) is","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"fracpartialpartial m L(ymDelta y) = fracpartialpartial m - frac(m-y)^22Delta y^2 = - frac(m-y)Delta y^2","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"∂_mL(y,m,Δy) = -(m-y)/(Δy^2)\nnothing # hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"Since the parameter in this example is one-dimensional, the gradient of the prior distribution is just the derivative. Thus, if the prior distribution is p_0(lambda) = - (lambda-1)^2,  the gradient is ","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"nabla p_0(lambda)= fracddlambda - lambda^2  = -2(lambda-1)","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"# Define the gradient for the prior as vector of functions.\n# Even in the 1-dim case.\n∇p_0 = [λ -> -2*(λ-1)]\nnothing # hide","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"The partial derivatives of the log-posterior can now be obtained with log_posterior_partials:","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"log_partials = log_posterior_partials(data_log_dists,model, ∂_mL, ∇p_0)","category":"page"},{"location":"log_posterior_implementation/","page":"How to implement","title":"How to implement","text":"log_partials[1](1.078)","category":"page"},{"location":"fitting_data/#FittingData-and-ModelFunctions-objects","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions objects","text":"","category":"section"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"using FittingObjectiveFunctions\nmodel = ModelFunctions((x,λ) -> λ*x)\nX = collect(1:10)\nY = [1.0, 1.78, 3.64, 3.72, 5.33, 2.73, 7.52, 9.19, 6.73, 8.95]\nΔY = [0.38, 0.86, 0.29, 0.45, 0.66, 2.46, 0.39, 0.45, 1.62, 1.54] \nnothing","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"For the construction of objective functions the data needs to be summarized in a FittingData object and information about the model needs to be summarized in a ModelFunctions object.","category":"page"},{"location":"fitting_data/#The-FittingData-struct","page":"FittingData and ModelFunctions","title":"The FittingData struct","text":"","category":"section"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"The FittingData struct has the following general constructor:","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"data = FittingData(X,Y,ΔY, distributions = distribution_functions)","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"The resulting object has the following fields:","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"data.independent == X\ndata.dependent == Y\ndata.errors == ΔY\ndata.distributions == distributions_functions","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"tip: Tip: shortened constructors\nIf no measurement errors ΔY are available, the shortened constructor can be used:FittingData(X,Y, distributions = distribution_functions)In this case, the default errors ones(length(X)) are used (leading e.g. to the standard least squares objective function: Background: LSQ)","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"tip: Tip: distributions\nThe optional distributions keyword is used to specify the likelihood distributions (see Background: Posterior probability). If distributions are not specified explicitly, the constructor defaults to normal distributions.The distributions can be specified as an array of functions, or a single function (the same distribution for all data points) with the signature (y,m,Δy), wherey is the measured dependent variable\nΔy is the corresponding error\nm are the values that the model function returns for a given parameter","category":"page"},{"location":"fitting_data/#The-ModelFunctions-struct","page":"FittingData and ModelFunctions","title":"The ModelFunctions struct","text":"","category":"section"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"ModelFunctions objects have the following general constructor:","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"model = ModelFunctions(model_function, partial_derivatives = [derivative_functions...])","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"The resulting object has the following fields:","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"model.model == model_function\nmodel.partials == [derivative_functions...]","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"The model function (and the partial derivatives) must have the signature (x,λ), where x is the independent variable and λ is the parameter (array).","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"tip: Tip: Partial derivatives\nThe keyword partials is optional, but is required for analytical partial derivatives and analytical gradient functions. The partial derivatives w.r.t. the parameter are defined as array of functions.textm(xlambda) = lambda_1 x + lambda_2  quad fracpartial textm(xlambda)partial lambda_1  = x  quad fracpartial textm(xlambda)partial lambda_1 = 1ModelFunctions((x,λ)-> λ[1]*x + λ[2], partials = [(x,λ)-> x, (x,λ)-> 1])","category":"page"},{"location":"fitting_data/#Additional-remarks","page":"FittingData and ModelFunctions","title":"Additional remarks","text":"","category":"section"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"When a FittingData/ModelFunctions object is created, some rudimentary consistency checks are done, e.g. that all arrays have the same lengths.","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"FittingData([1,2,3],[1,2],[1,1,1])","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"Since the objects are mutable, the same consistency checks are repeated before objective functions are created. However, it can be useful to make a comprehensive consistency check. For this, a representative parameter (array) is needed:","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"data = FittingData(X,Y)\nmodel = ModelFunctions((x,λ)-> λ*x)\nconsistency_check(data,model,1)","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"If everything works, nothing is returned, i.e. nothing happens. However, in case of a problem, an error is thrown:","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"consistency_check(data,model,\"1\")","category":"page"},{"location":"fitting_data/","page":"FittingData and ModelFunctions","title":"FittingData and ModelFunctions","text":"note: Mutability of objects\nBoth FittingData objects and ModelFunctions objects are mutable for convenience, as they are not performance relevant (only their fields are). However, when objective functions are created, the object fields are copied and enclosed in the objective function, to avoid accidental mutation. I.e. once an objective function is created, it does not change, even if the FittingData/ModelFunctions objects are changed. To apply changes, a new objective function needs to be created. ","category":"page"},{"location":"posterior_background/#Background:-Posterior-probability","page":"Background","title":"Background: Posterior probability","text":"","category":"section"},{"location":"posterior_background/","page":"Background","title":"Background","text":"The posterior objective (and the logarithmic posterior objective which is numerically favorable) allows to define general objective functions. Form a Bayesian perspective, one is interested in the probability density of the parameters lambda = lambda_1ldotslambda_n given the data x_i_i=1^N y_i_i=1^N and the model m(xlambda):","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"p(lambda mid x_i_i=1^N y_i_i=1^N m)","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"The following explanations are largely based on and extended from","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"Bayesian inference (Wikipedia)\nBayesian linear regression (Wikipedia)\nStraight line fitting - a Bayesian solution (E. T. Jaynes, unpublished)","category":"page"},{"location":"posterior_background/#Applying-Bayes'-theorem","page":"Background","title":"Applying Bayes' theorem","text":"","category":"section"},{"location":"posterior_background/","page":"Background","title":"Background","text":"Using Bayes' theorem, the probability density can be rewritten as:","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"p(lambda mid x_i_i=1^N y_i_i=1^N m) = fracell(y_i_i=1^N mid x_i_i=1^N  lambda m )cdot p_0(lambdamid x_i_i=1^N m)p(y_i_i=1^N mid x_i_i=1^N  m)","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"The denominator is but a normalization constant, that does not depend on lambda, i.e. can be ignored for optimization problems (and MCMC sampling):","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"p(lambda mid x_i_i=1^N y_i_i=1^N m) propto ell(y_i_i=1^N mid x_i_i=1^N  lambda m )cdot p_0(lambdamid x_i_i=1^N m)","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"Because of the proportionality, one may refer to the right hand side as unnormalized posterior.","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"ell is a proper probability density function for y_i_i=1^N given x_i_i=1^N lambda m. However, it can also be regarded as function of lambda, for fixed x_i_i=1^N, y_i_i=1^N and m (which is needed, since the data is fixed, but different parameters need to be tested during the model fitting). In this case, one calls it the likelihood function of lambda. It is no longer a proper probability density (still positive but no longer normalized).\np_0 is called prior distribution. It determines the probability of the parameters, before the data was obtained. This is sometimes called belief in parameters or initial knowledge.","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"default: The prior and objectivity\nA common criticism is that the prior is not objective. While the choice of prior can be subjective, it must be explicitly stated, making all assumptions transparent. This allows for an objective comparison of the different approaches.In fact, there are two common types of priors in least squares fitting.p_0(lambdamid x_i_i=1^N m) = 1, i.e. a uniform prior. Since one usually uses a computer, there is a largest number b infty and a smallest number a  -infty that the computer can use. Then one may choose the uniform distribution p_0(lambda mid x_i_i=1^N m) = frac1b-a. Sine the posterior probability is only considered up to proportionality, one can simply use p_0(lambdamid x_i_i=1^N m) = 1. This leads to a maximum likelihood objective.\nIn ill-defined problems, it is common practice to use some kind of regularization. In some cases, these regularizations correspond to certain priors. For example, the Tikhonov regularization essentially uses the prior p_0(lambdamid x_i_i=1^N m) propto exp(-Gamma lambda ^2).","category":"page"},{"location":"posterior_background/#Independent-data-points","page":"Background","title":"Independent data points","text":"","category":"section"},{"location":"posterior_background/","page":"Background","title":"Background","text":"A common assumption is that the data points are independent. While this is not a necessity, writing general likelihood functions is usually not trivial. If the data points are independent, the likelihood function becomes a product of likelihood functions for the individual data point likelihoods:","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"ell(y_i_i=1^N mid lambda x_i_i=1^N m ) = prod_i=1^N ell_i(y_imid lambda x_i m)","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"Note that the likelihoods can differ for the different data points, here denoted by ell_i.  Thus the posterior distribution becomes","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"p(lambda mid x_i_i=1^N y_i_i=1^N m) propto  p_0(lambdamid x_i_i=1^N m) prod_i=1^n ell_i(y_imid lambda x_im)","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"In general, the independent variable x_i is a measured quantity, where the true value mathcalX_i is unknown. If the density function p_i(mathcalX_imid lambda x_i m) of true values mathcalX_i is known, marginalization can be used to express the likelihood","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"ell_i(y_imid lambda x_i m) = int ell_i(y_i mid mathcalX_i lambda x_i m)cdot p_I(mathcalX_imid lambda x_im)  dmathcalX_i","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"The likelihood ell_i(y_imid mathcalX_i lambda x_i m) is essentially given by the probability density function q_i(y_imid mathcalY_i) to measure the value y_i when the true value is mathcalY_i. Since mathcalY_i = m(mathcalX_ilambda) by assumption of the model it follows that","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"ell_i(y_i mid mathcalX_i lambda x_i m) = q_i(y_imid m(mathcalX_i lambda))","category":"page"},{"location":"posterior_background/#No-x-uncertainty","page":"Background","title":"No x-uncertainty","text":"","category":"section"},{"location":"posterior_background/","page":"Background","title":"Background","text":"A convenient situation is, when the distinction between x_i and mathcalX_i can be neglected, e.g. because the independent variable can be measured with high precision. Then p_i(mathcalX_imid lambda x_i m) becomes a Dirac distribution, and","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"ell_i(y_imid lambda x_i m) = q_i(y_imid m(x_ilambda))","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"Hence, the posterior distribution reads ","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"p(lambda mid x_i_i=1^N y_i_i=1^N m) propto  p_0(lambdamid x_i_i=1^N m) prod_i=1^n q_i(y_imid m(x_ilambda))","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"tip: Implementing x-uncertainties\nIn most examples of this documentation, it is assumed that there is no x-uncertainty, as it is often impossible to solve the x-uncertainty integral. Hence, the likelihoods ell_i for the individual data points are simply referred to as y-uncertainty distributions q_i, in most parts of the documentation. However, if the x-uncertainty integral can be solved analytically or can be approximated efficiently, the likelihoods ell_i can be used instead of the y-uncertainty distributions q_i.","category":"page"},{"location":"posterior_background/#Retrieving-the-LSQ-objective","page":"Background","title":"Retrieving the LSQ objective","text":"","category":"section"},{"location":"posterior_background/","page":"Background","title":"Background","text":"Using the aforementioned uniform prior p_0(lambdamid x_i_i=1^N m) = 1 and assuming normal distributions for the q_i with standard deviations Delta y_i leads to","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"beginaligned\np(lambda mid x_i_i=1^N y_i_i=1^N m) propto   prod_i=1^n frac1sqrt2piDelta y_iexpleft(- frac(y_i - m(x_ilambda))^22Delta y_i^2right)  \npropto prod_i=1^n expleft(- frac(y_i - m(x_ilambda))^22Delta y_i^2right) \n quad = expleft(- sum_i=1^N frac(y_i - m(x_ilambda))^22Delta y_i^2right)\nendaligned","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"Maximizing this function is equivalent to minimizing","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"sum_i=1^N frac(y_i - m(x_ilambda))^22Delta y_i^2","category":"page"},{"location":"posterior_background/","page":"Background","title":"Background","text":"which is the weighted least squares objective, up to a factor frac12 (see Background: LSQ).","category":"page"},{"location":"lsq_background/#Background:-LSQ","page":"Background","title":"Background: LSQ","text":"","category":"section"},{"location":"lsq_background/","page":"Background","title":"Background","text":"For data points (x_iy_iDelta y_i)_i=1^N, the (weighted) least squares objective function (cf. Wikipedia) is","category":"page"},{"location":"lsq_background/","page":"Background","title":"Background","text":"textlsq(lambda) = sum_i=1^N frac(y_i - m(x_ilambda))^2Delta y_i^2","category":"page"},{"location":"lsq_background/","page":"Background","title":"Background","text":"For the standard least squares objective function, one sets Δy_i = 1 for all i = 1ldotsn.","category":"page"},{"location":"lsq_background/","page":"Background","title":"Background","text":"The optimal parameters lambda = lambda_1ldots lambda_n, given the data (x_iy_iDelta y_i) and the model function m(xlambda), are those that minimize the least squares objective function textlsq(lambda). An explanation for this statement can be found in Background:-Posterior-probability","category":"page"},{"location":"posterior_implementation/#Posterior-probability:-How-to-implement","page":"How to implement","title":"Posterior probability: How to implement","text":"","category":"section"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"Consider the data and model from Simple-example:","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"using FittingObjectiveFunctions, Plots #hide\n\nX = collect(1:10)\nY = [1.0, 1.78, 3.64, 3.72, 5.33, 2.73, 7.52, 9.19, 6.73, 8.95]\nΔY = [0.38, 0.86, 0.29, 0.45, 0.66, 2.46, 0.39, 0.45, 1.62, 1.54]\ndata = FittingData(X,Y,ΔY)\nmodel = ModelFunctions((x,λ)-> λ*x)\n\nnothing #hide","category":"page"},{"location":"posterior_implementation/#Likelihood-functions","page":"How to implement","title":"Likelihood functions","text":"","category":"section"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"A likelihood function can be obtained with posterior_objective by omitting the definition of a prior distribution:","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"lsq_likelihood = posterior_objective(data,model)","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"Like lsq_objective, posterior_objective returns a function that takes the model parameter (array) λ as argument.","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"Observer that no distributions were specified in the constructor for data. As explained in The FittingData struct, the constructor uses normal distributions in this case. Thus, the obtained likelihood function lsq_likelihood  corresponds to the weighted least squares objective (see Retrieving the LSQ objective).","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"Normal distributions are not the only possible y-uncertainty distributions (q_i(y_i mid m(x_ilambda))). For example, one might assume a heavy-tailed distribution for measurements, e.g. a Cauchy distribution:","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"using Distributions #hide\nplot(x-> pdf(Normal(0,1),x), label = \"Normal(0,1)\") #hide\nplot!(x-> pdf(Cauchy(0,1),x), label = \"Cauchy(0,1)\") #hide","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"To modify the y-uncertainty distributions, the FittingData object must be redefined (cf. The FittingData struct). The distributions must have the signature (y,m,Δy):","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"cauchy(y,m,Δy) = pdf(Cauchy(m,Δy),y)\ndata_cauchy = FittingData(X,Y,ΔY,distributions = cauchy)\nnothing #hide","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"Now a likelihood function with Cauchy uncertainty distributions can be created:","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"cauchy_likelihood = posterior_objective(data_cauchy,model)","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"To compare the shape of the resulting likelihood functions, it is helpful to rescale the cauchy_likelihood, such that the maxima have the same height:","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"large_scope = plot(lsq_likelihood, xlims = [0.9,1.2], label=\"lsq_likelihood\", legend = :topleft) #hide\nplot!(x-> 16 * cauchy_likelihood(x), label = \"cauchy_likelihood\") #hide\nsmall_scope =  plot(lsq_likelihood, xlims = [1.0725,1.0825], legend = :none) #hide\nplot!(x-> 16 * cauchy_likelihood(x)) #hide\nplot(large_scope,small_scope, layout = (1,2), size = (800,300))#hide","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"tip: Individual distributions\nIt is possible to define a distribution for each data point. Furthermore, these functions can be general Julia functions. While the input arguments must be (y,m,Δy), they need not be utilized in the function.For example, we can assign normal distributions with σ=1 for the first 5 data points, and Cauchy distributions width sigma_i = Delta y_i for the remaining data points:normal_dists = [(y,m,Δy)-> pdf(Normal(m,1),y) for i in 1:5]\ncauchy_dists = [(y,m,Δy)-> pdf(Cauchy(m,Δy),y) for i in 6:length(Y)]\ndata_example = FittingData(X,Y,ΔY, distributions = vcat(normal_dists...,cauchy_dists...))\nlikelihood = posterior_objective(data_example,model)","category":"page"},{"location":"posterior_implementation/#Using-priors","page":"How to implement","title":"Using priors","text":"","category":"section"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"As described in the remark about the objectivity of priors, one always retrieves the likelihood function, when using a uniform prior (over the range of computer representable numbers). This is in fact what happened in the examples Likelihood-functions, as posterior_objective has an optional argument:","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"posterior_objective(data::FittingData,model::ModelFunction,prior::Function= λ -> 1)","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"This means, whenever only the two arguments data and model are provided, the last argument defaults to λ-> 1. To specify a certain prior, one just needs to pass it as third argument. ","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"For example, the theory and/or other measurements could indicate that the true parameter value should be lambda = 1. To implement a normal distribution with mu =1 and sigma = 01 as prior, the third argument must be the pdf function for said normal distribution (here using the build in pdf function from Distributions.jl):","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"using Distributions\nposterior = posterior_objective(data,model,λ-> pdf(Normal(1,0.1),λ))","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"Again, since the posterior and the likelihood are not properly normalized, rescaling is necessary to compare the shapes of lsq_likelihood and posterior:","category":"page"},{"location":"posterior_implementation/","page":"How to implement","title":"How to implement","text":"large_scope = plot(x-> 10/3.3*lsq_likelihood(x), xlims = [0.9,1.2], label = \"lsq_likelihood\", legend = :topleft) #hide\nplot!(posterior, label = \"posterior\")  #hide\nsmall_scope = plot(x-> 10/3.3*lsq_likelihood(x), xlims = [1.065,1.085], legend = :none) #hide\nplot!(posterior)  #hide\nplot(large_scope,small_scope, layout = (1,2), size = (800,300)) #hide","category":"page"},{"location":"#FittingObjectiveFunctions","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"","category":"section"},{"location":"#About","page":"FittingObjectiveFunctions","title":"About","text":"","category":"section"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"FittingObjectiveFunctions.jl is a lightweight package without dependencies to create objective functions for model fitting. This package does not include optimizers/samplers.","category":"page"},{"location":"#Installation","page":"FittingObjectiveFunctions","title":"Installation","text":"","category":"section"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"The package can be installed with the following commands","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"using Pkg\nPkg.Registry.add()\nPkg.Registry.add(RegistrySpec(url = \"https://github.com/Translational-Pain-Research/Translational-Pain-ResearchRegistry\"))\nPkg.add(\"FittingObjectiveFunctions\")","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"Since the package is not part of the General registry the commands install the additional registry Translational-Pain-ResearchRegistry first.","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"After the installation, the package can be used like any other package:","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"using FittingObjectiveFunctions","category":"page"},{"location":"#Simple-example","page":"FittingObjectiveFunctions","title":"Simple example","text":"","category":"section"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"Consider the following example data-set:","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"using Plots\n\nX = collect(1:10)\nY = [1.0, 1.78, 3.64, 3.72, 5.33, 2.73, 7.52, 9.19, 6.73, 8.95]\nΔY = [0.38, 0.86, 0.29, 0.45, 0.66, 2.46, 0.39, 0.45, 1.62, 1.54]\n\nscatter(X,Y, yerror = ΔY, legend=:none, xlabel = \"X\", ylabel=\"Y\")","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"Before objective functions can be created, the data needs to be summarized in a FittingData object:","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"data = FittingData(X,Y,ΔY)\nnothing #hide","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"Information about the model needs to be summarized in a ModelFunctions object. Here we choose a simple linear model m(xlambda) = lambda x:","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"model = ModelFunctions((x,λ) -> λ*x) \nnothing #hide","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"A weighted least squares objective can be be constructed as follows:","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"lsq = lsq_objective(data,model)","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"The following plot (not part of this package) shows the connection between the data points, the parameter λ of the model m(x,λ) and the least squares objective lsq:","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"using ColorSchemes, Measures\n\ncmap = cgrad(:thermal)\n\ndata_plot = plot(; xlabel = \"X\", ylabel=\"Y\", xlims = [0,maximum(X)+0.5])\nfor δ in 0.4:-0.1:0.1\n\tplot!(x->(1+δ)x, label = \"λ=$(1+δ)\", color = cmap[0.5 + δ/0.8], linewidth= 3)\nend\nplot!(x->x, label = \"λ=1\", color = cmap[0.5], linewidth = 3)\nfor δ in 0.1:0.1:0.4\n\tplot!(x->(1-δ)x, label = \"λ=$(1-δ)\", color = cmap[0.5 - δ/0.8], linewidth = 3)\nend\nscatter!(X,Y, yerror = ΔY, color = 1, label = \"data\", markersize = 6)\nannotate!(5,14,\"m(x,λ) = λ⋅x\")\n\nlsq_plot = plot(; legend = :top, xlabel = \"λ\", ylabel = \"lsq\", xlims = [0.5,1.5]) \nplot!(λ-> lsq(λ), linewidth= 3, label = \"lsq\")\nfor δ in 0.4:-0.1:0.1\n\tscatter!([(1+δ)],[lsq(1+δ)], label = \"λ=$(1+δ)\", color = cmap[0.5 + δ/0.8], markersize = 5)\nend\nscatter!([(1)],[lsq(1)], label = \"λ=1\", color = cmap[0.5], markersize = 5)\nfor δ in 0.1:0.1:0.4\n\tscatter!([(1-δ)],[lsq(1-δ)], label = \"λ=$(1-δ)\", color = cmap[0.5 - δ/0.8], markersize = 5)\nend\n","category":"page"},{"location":"","page":"FittingObjectiveFunctions","title":"FittingObjectiveFunctions","text":"plot(data_plot,lsq_plot, layout = (1,2), size = (900,400), bottom_margin = 5mm, left_margin = 5mm) # hide","category":"page"},{"location":"lsq_implementation/#LSQ:-How-to-implement","page":"How to implement","title":"LSQ: How to implement","text":"","category":"section"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"Consider the data and model from Simple example:","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"using FittingObjectiveFunctions, Plots #hide\n\nX = collect(1:10)\nY = [1.0, 1.78, 3.64, 3.72, 5.33, 2.73, 7.52, 9.19, 6.73, 8.95]\nΔY = [0.38, 0.86, 0.29, 0.45, 0.66, 2.46, 0.39, 0.45, 1.62, 1.54]\ndata = FittingData(X,Y,ΔY)\nmodel = ModelFunctions((x,λ)-> λ*x)\n\nnothing #hide","category":"page"},{"location":"lsq_implementation/#Objective-functions","page":"How to implement","title":"Objective functions","text":"","category":"section"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"Use lsq_objective to construct the uncertainty-weighted least squares objective: ","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"weighted_lsq = lsq_objective(data,model)","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"The returned objective function takes the model parameter (array) λ as argument weighted_lsq(λ).","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"To obtain the standard least squares objective, the errors must be set to 1, e.g. by using the shortened constructor (see The FittingData struct):","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"data_no_errors = FittingData(X,Y)\nstandard_lsq = lsq_objective(data_no_errors,model)\nw_lsq_plot = plot(weighted_lsq, label = \"weighted lsq\", xlims = [0,2], xlabel = \"λ\", ylabel = \"lsq\") #hide\nplot!(standard_lsq, label = \"standard lsq\", xlims = [0,2], xlabel = \"λ\", ylabel = \"lsq\", color = 2) #hide","category":"page"},{"location":"lsq_implementation/#lsq_derivatives","page":"How to implement","title":"Partial derivatives and gradients","text":"","category":"section"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"To obtain partial derivatives or the gradient of the least squares objective function, the partial derivatives of the model function need to be added to the ModelFunctions object (cf. The ModelFunctions struct):","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"model = ModelFunctions((x,λ)->λ*x , partials = [(x,λ)-> x])","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"The partial derivatives of the least squares objective can be obtained with lsq_partials","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"∂_weighted_lsq = lsq_partials(data,model)","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"Note that lsq_partials returns the partial derivatives as vector of abstract functions with λ as argument, even in the 1-dimensional case.","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"∂_weighted_lsq[1](1.1)","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"The gradient of the least squares objective can be obtained with lsq_gradient","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"∇_weighted_lsq = lsq_gradient(data,model) ","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"The returned gradient function has the signature (grad_vector,λ). The argument grad_vector must be a vector of appropriate type and length, that can be mutated.","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"∇_weighted_lsq([0.0],1.1) ","category":"page"},{"location":"lsq_implementation/","page":"How to implement","title":"How to implement","text":"info: Mutation of gradient vector\nIn some optimization algorithms, the gradient function is called multiple times during each iteration. Mutating an array allows to reduce the memory allocation overhead of creating new gradient arrays.","category":"page"},{"location":"API/#API","page":"API","title":"API","text":"","category":"section"},{"location":"API/#The-FittingData-type","page":"API","title":"The FittingData type","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"FittingData","category":"page"},{"location":"API/#FittingObjectiveFunctions.FittingData","page":"API","title":"FittingObjectiveFunctions.FittingData","text":"mutable struct FittingData\n\nData type for fitting data.\n\nThis struct is only a container to check consistency and is not performance relevant, hence the mutability.\n\nFields\n\nindependent: Array of data points for the independent variable. \ndependent: Array of data points for the dependent variable.\nerrors: Array of measurement errors for the dependent variable.\ndistributions: Distribution(s) for the uncertainty of the dependent variable. Can be a function or an array of functions (one for each data point). \n\nElements with the same index belong together, i.e. define a measurement: \n\n(independent[i], dependent[i], errors[i], distributions[i])\n\nConstructors\n\nFittingData(X,Y)\n\nFittingData(X,Y,ΔY;distributions = (y,m,Δy) -> exp(-(y-m)^2/(2*Δy^2))/(sqrt(2*pi) * Δy))\n\nDistributions\n\nThe distributions must have the signature (y,m,Δy), where y is the dependent variable, m is the result of the model function and Δy is the error of the dependent variable. If the distributions are not specified, a normal distribution is used:\n\n(y,m,Δy) -> exp(-(y-m)^2/(2*Δy^2))/(sqrt(2*pi) * Δy)\n\n\n\n\n\n","category":"type"},{"location":"API/#The-ModelFunctions-type","page":"API","title":"The ModelFunctions type","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"ModelFunctions","category":"page"},{"location":"API/#FittingObjectiveFunctions.ModelFunctions","page":"API","title":"FittingObjectiveFunctions.ModelFunctions","text":"mutable struct ModelFunctions\n\nMutable type to collect model functions (and the respective partial derivatives) to construct objective functions.\n\nThis struct is only a container to check consistency and is not performance relevant, hence the mutability.\n\nFields\n\nmodel: The model function. Must have the signature (x,λ), where x is the independent variable, and λ is the parameter (array).\npartials: Array of partial derivative functions (one for each parameter array element). Must have the same signature (x,λ) as the model function.\n\nConstructor\n\nModelFunctions(model, partials = nothing)\n\nExamples\n\njulia> ModelFunctions((x,λ)-> λ*x)\t\n\njulia> ModelFunctions((x,λ)-> λ*x, partials = [(x,λ)-> x])\t\n\njulia> ModelFunctions((x,λ)-> λ[1]*x+λ[2], partials = [(x,λ)-> x, (x,λ)-> 1])\t\n\n\n\n\n\n","category":"type"},{"location":"API/","page":"API","title":"API","text":"consistency_check","category":"page"},{"location":"API/#FittingObjectiveFunctions.consistency_check","page":"API","title":"FittingObjectiveFunctions.consistency_check","text":"consistency_check(fitting_data::FittingData,model::ModelFunctions)\n\nTest fitting_data and model, e.g. after mutation. \n\n\n\n\n\nconsistency_check(fitting_data::FittingData,model::ModelFunctions,λ)\n\nTest if all functions can be evaluated with the parameter (array) λ. Also, test fitting_data and model, e.g. after mutation. \n\n\n\n\n\n","category":"function"},{"location":"API/#Least-squares-objective","page":"API","title":"Least squares objective","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"lsq_objective","category":"page"},{"location":"API/#FittingObjectiveFunctions.lsq_objective","page":"API","title":"FittingObjectiveFunctions.lsq_objective","text":"lsq_objective(data::FittingData,model::ModelFunctions)\n\nReturn the least squares objective as function λ -> lsq(λ).\n\nAnalytical expression\n\nindependent data points x_i\ndependent data points y_i\nerrors Delta y_i\nmodel function m\n\ntextlsq(lambda) = sum_i=1^N frac(y_i - m(x_ilambda))^2Delta y_i^2\n\n\n\n\n\n","category":"function"},{"location":"API/","page":"API","title":"API","text":"lsq_partials","category":"page"},{"location":"API/#FittingObjectiveFunctions.lsq_partials","page":"API","title":"FittingObjectiveFunctions.lsq_partials","text":"lsq_partials(data::FittingData,model::ModelFunctions)\n\nReturn the partial derivatives of the least squares objective function ob(λ) as array of functions [λ->∂_1 ob(λ),…,λ->∂_n ob(λ)] .\n\nThe partial derivatives fracpartialpartial lambda_mu m(xlambda) of the model function must be specified in the ModelFunctions object model.\n\nAnalytical expression\n\nindependent data points: x_i\ndependent data points: y_i\nerrors: Delta y_i\nmodel function: m\npartial derivatives of model function in: fracpartialpartial lambda_mum(xlambda)\n\n fracpartialpartial lambda_mu textlsq(lambda) = sum_i=1^N frac 2 cdot (m(x_ilambda) - y_i) cdot fracpartialpartial lambda_mu m(xlambda)Delta y_i^2\n\n\n\n\n\n","category":"function"},{"location":"API/","page":"API","title":"API","text":"lsq_gradient","category":"page"},{"location":"API/#FittingObjectiveFunctions.lsq_gradient","page":"API","title":"FittingObjectiveFunctions.lsq_gradient","text":"lsq_gradient(data::FittingData,model::ModelFunctions)\n\nReturn the gradient of the least squares objective function ob(λ) as function (gradient,λ)->grad!(gradient,λ) .\n\nThe gradient function grad! mutates (for performance) and returns the gradient. The elements of gradient do not matter, but the type and length must fit.\nThe partial derivatives fracpartialpartial lambda_mu m(xlambda) of the model function must be specified in the ModelFunctions object model.\n\nAnalytical expression\n\nindependent data points: x_i\ndependent data points: y_i\nerrors: Delta y_i\nmodel function: m\npartial derivatives of model function in: fracpartialpartial lambda_mum(xlambda)\n\nnabla textlsq(lambda) =  sum_mu  left(sum_i=1^N frac 2 cdot (m(x_ilambda) - y_i) cdot fracpartialpartial lambda_mum(xlambda) Delta y_i^2 right) vece_mu\n\n\n\n\n\n","category":"function"},{"location":"API/#Posterior-objective","page":"API","title":"Posterior objective","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"posterior_objective","category":"page"},{"location":"API/#FittingObjectiveFunctions.posterior_objective","page":"API","title":"FittingObjectiveFunctions.posterior_objective","text":"posterior_objective(data::FittingData, \n\tmodel::Function,distribution::Function, \n\tprior = λ-> 1\n)\n\nReturn the unnormalized posterior density as function λ->p(λ).\n\nUsing the default prior λ-> 1, e.g. py passing only the first two arguments, leads to the likelihood objective for a maximum likelihood fit.\n\nAnalytical expression\n\nindependent data points x_i\ndependent data points y_i\nerrors Delta y_i\nmodel function m\ny-uncertainty distributions: q_i\nprior distribution: p_0\n\np(lambda) = p_0(lambda) cdot prod_i=1^N q_i(y_im(x_ilambda)Delta y_i)\n\n\n\n\n\n","category":"function"},{"location":"API/","page":"API","title":"API","text":"log_posterior_objective","category":"page"},{"location":"API/#FittingObjectiveFunctions.log_posterior_objective","page":"API","title":"FittingObjectiveFunctions.log_posterior_objective","text":"log_posterior_objective(data::FittingData,\n\tmodel::ModelFunctions, \n\tlog_prior::Function = log_uniform_prior\n)\n\nReturn the logarithmic posterior density as function λ->L_p(λ). \n\nThe y-uncertainty distributions of the FittingData object data and log-prior must be specified in the logarithmic form.\n\nUsing the default prior, e.g. py passing only the first two arguments, leads to the logarithmic likelihood objective for a maximum likelihood fit.\n\nAnalytical expression\n\nindependent data points x_i\ndependent data points y_i\nerrors Delta y_i\nmodel function m\nlogarithmic y-uncertainty distributions: L_i\nlogarithmic prior distribution: L_0\n\nL_p(lambda) = L_0(lambda) + sum_i=1^N L_i(y_im(x_ilambda)Delta y_i)\n\n\n\n\n\n","category":"function"},{"location":"API/","page":"API","title":"API","text":"log_posterior_partials","category":"page"},{"location":"API/#FittingObjectiveFunctions.log_posterior_partials","page":"API","title":"FittingObjectiveFunctions.log_posterior_partials","text":"log_posterior_partials(data::FittingData,\n\tmodel::ModelFunctions,\n\tlog_distribution_derivatives, \n\tprior_partials::Union{Nothing,AbstractArray{Function,N}} = nothing\n)\n\nReturn the partial derivatives of the log-posterior distribution L_p(λ) as array of functions [λ->∂_1 L_p(λ),…,λ->∂_n L_p(λ)].\n\nThe partial derivatives fracpartialpartial lambda_mu m(xlambda) of the model function must be specified in the ModelFunctions object model.\nlog_distribution_derivatives can either be a function fracpartialpartial m L(ymDelta y) (same derivative for all distributions), or an array of functions leftfracpartialpartial m L_1(ymDelta y)ldotsfracpartialpartial m L_n(ymDelta y) right\nprior_partials can either be nothing (for the log-likelihood), or an array of functions leftfracpartialpartial lambda_1 L_0(λ)ldotsfracpartialpartial lambda_n L_0(λ) right.\n\nAnalytical expression\n\nindependent data points x_i\ndependent data points y_i\nerrors Delta y_i\nmodel function m\nlogarithmic y-uncertainty distributions: L_i\nlogarithmic prior distribution: L_0\npartial derivatives of model function: fracpartialpartial lambda_mu m(xlambda)\npartial derivatives of the logarithmic y-uncertainty distributions: fracpartialpartial m L_i(ymDelta y)\npartial derivatives of the logarithmic prior: fracpartialpartial lambda_mu L_0(λ)\n\nfracpartialpartial lambda_mu L_p(lambda) = fracpartialpartial lambda_mu L_0(lambda) + sum_i=1^N  fracpartialpartial m L_i(y_i m(x_ilambda) Delta y_i)cdot fracpartialpartial lambda_mu m(x_ilambda)\n\n\n\n\n\n","category":"function"},{"location":"API/","page":"API","title":"API","text":"log_posterior_gradient","category":"page"},{"location":"API/#FittingObjectiveFunctions.log_posterior_gradient","page":"API","title":"FittingObjectiveFunctions.log_posterior_gradient","text":"log_posterior_gradient(data::FittingData,\n\tmodel::ModelFunctions, \n\tlog_distribution_derivatives, \n\tprior_partials::Union{Nothing,AbstractArray{Function,N}} = nothing\n)\n\nReturn the gradient of the log-posterior distribution L_p(λ) as function (gradient,λ)->grad!(gradient,λ) .\n\nThe gradient function grad! mutates (for performance) and returns the gradient. The elements of gradient do not matter, but the type and length must fit.\nThe partial derivatives fracpartialpartial lambda_mu m(xlambda) of the model function must be specified in the ModelFunctions object model.\nlog_distribution_derivatives can either be a function fracpartialpartial m L(ymDelta y) (same derivative for all distributions), or an array of functions leftfracpartialpartial m L_1(ymDelta y)ldotsfracpartialpartial m L_n(ymDelta y) right\nprior_partials can either be nothing (for the log-likelihood), or an array of functions leftfracpartialpartial lambda_1 L_0(λ)ldotsfracpartialpartial lambda_n L_0(λ) right.\n\nAnalytical expression\n\nindependent data points x_i\ndependent data points y_i\nerrors Delta y_i\nmodel function m\nlogarithmic y-uncertainty distributions: L_i\nlogarithmic prior distribution: L_0\npartial derivatives of model function: fracpartialpartial lambda_mu m(xlambda)\npartial derivatives of the logarithmic y-uncertainty distributions: fracpartialpartial m L_i(ymDelta y)\npartial derivatives of the logarithmic prior: fracpartialpartial lambda_mu L_0(λ)\n\nnabla L_p(lambda) = sum_mu left( fracpartialpartial lambda_mu L_0(lambda) + sum_i=1^N  fracpartialpartial m L_i(y_i m(x_ilambda) Delta y_i)cdot fracpartialpartial lambda_mu m(x_ilambda) right) vece_mu\n\n\n\n\n\n","category":"function"}]
}
