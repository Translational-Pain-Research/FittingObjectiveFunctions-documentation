<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Background · FittingObjectiveFunctions.jl</title><meta name="title" content="Background · FittingObjectiveFunctions.jl"/><meta property="og:title" content="Background · FittingObjectiveFunctions.jl"/><meta property="twitter:title" content="Background · FittingObjectiveFunctions.jl"/><meta name="description" content="Documentation for FittingObjectiveFunctions.jl."/><meta property="og:description" content="Documentation for FittingObjectiveFunctions.jl."/><meta property="twitter:description" content="Documentation for FittingObjectiveFunctions.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="FittingObjectiveFunctions.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">FittingObjectiveFunctions.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">FittingObjectiveFunctions</a></li><li><a class="tocitem" href="../fitting_data/">FittingData and ModelFunctions</a></li><li><span class="tocitem">Least squares objective</span><ul><li><a class="tocitem" href="../lsq_background/">Background</a></li><li><a class="tocitem" href="../lsq_implementation/">How to implement</a></li></ul></li><li><span class="tocitem">Posterior probability</span><ul><li class="is-active"><a class="tocitem" href>Background</a><ul class="internal"><li><a class="tocitem" href="#Applying-Bayes&#39;-theorem"><span>Applying Bayes&#39; theorem</span></a></li><li><a class="tocitem" href="#Independent-data-points"><span>Independent data points</span></a></li><li><a class="tocitem" href="#No-x-uncertainty"><span>No <span>$x$</span>-uncertainty</span></a></li><li><a class="tocitem" href="#Retrieving-the-LSQ-objective"><span>Retrieving the LSQ objective</span></a></li></ul></li><li><a class="tocitem" href="../posterior_implementation/">How to implement</a></li></ul></li><li><span class="tocitem">Logarithmic posterior probability</span><ul><li><a class="tocitem" href="../log_posterior_background/">Background</a></li><li><a class="tocitem" href="../log_posterior_implementation/">How to implement</a></li></ul></li><li><a class="tocitem" href="../API/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Posterior probability</a></li><li class="is-active"><a href>Background</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Background</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Translational-Pain-Research/FittingObjectiveFunctions.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Translational-Pain-Research/FittingObjectiveFunctions.jl/blob/main/docs/src/posterior_background.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Background:-Posterior-probability"><a class="docs-heading-anchor" href="#Background:-Posterior-probability">Background: Posterior probability</a><a id="Background:-Posterior-probability-1"></a><a class="docs-heading-anchor-permalink" href="#Background:-Posterior-probability" title="Permalink"></a></h1><p>The posterior objective (and the <a href="#Log-posterior-objective">logarithmic posterior objective</a> which is numerically favorable) allows to define general objective functions. Form a Bayesian perspective, one is interested in the probability density of the parameters <span>$\lambda = \{\lambda_1,\ldots,\lambda_n\}$</span> given the data <span>$\{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N$</span> and the model <span>$m(x,\lambda)$</span>:</p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m)\]</p><p>The following explanations are largely based on and extended from</p><ul><li><a href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian inference (Wikipedia)</a></li><li><a href="https://en.wikipedia.org/wiki/Bayesian_statistics">Bayesian linear regression (Wikipedia)</a></li><li><a href="https://bayes.wustl.edu/etj/articles/leapz.pdf">Straight line fitting - a Bayesian solution (E. T. Jaynes, unpublished)</a></li></ul><h2 id="Applying-Bayes&#39;-theorem"><a class="docs-heading-anchor" href="#Applying-Bayes&#39;-theorem">Applying Bayes&#39; theorem</a><a id="Applying-Bayes&#39;-theorem-1"></a><a class="docs-heading-anchor-permalink" href="#Applying-Bayes&#39;-theorem" title="Permalink"></a></h2><p>Using Bayes&#39; theorem, the probability density can be rewritten as:</p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) = \frac{\ell(\{y_i\}_{i=1}^N \mid \{x_i\}_{i=1}^N , \lambda, m )\cdot p_0(\lambda\mid \{x_i\}_{i=1}^N, m)}{p(\{y_i\}_{i=1}^N \mid \{x_i\}_{i=1}^N , m)}\]</p><p>The denominator is but a normalization constant, that does not depend on <span>$\lambda$</span>, i.e. can be ignored for optimization problems (and MCMC sampling):</p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) \propto \ell(\{y_i\}_{i=1}^N \mid \{x_i\}_{i=1}^N , \lambda, m )\cdot p_0(\lambda\mid \{x_i\}_{i=1}^N, m)\]</p><p>Because of the proportionality, one may refer to the right hand side as <strong>unnormalized posterior</strong>.</p><ul><li><p><span>$\ell$</span> is a proper probability density function for <span>$\{y_i\}_{i=1}^N$</span> given <span>$\{x_i\}_{i=1}^N, \lambda, m$</span>. However, it can also be regarded as function of <span>$\lambda$</span>, for fixed <span>$\{x_i\}_{i=1}^N$</span>, <span>$\{y_i\}_{i=1}^N$</span> and <span>$m$</span> (which is needed, since the data is fixed, but different parameters need to be tested during the model fitting). In this case, one calls it the <strong>likelihood</strong> function of <span>$\lambda$</span>. It is no longer a proper probability density (still positive but no longer normalized).</p></li><li><p><span>$p_0$</span> is called <strong>prior</strong> distribution. It determines the probability of the parameters, before the data was obtained. This is sometimes called <em>belief in parameters</em> or <em>initial knowledge</em>.</p></li></ul><div class="admonition is-category-default"><header class="admonition-header">The prior and objectivity</header><div class="admonition-body"><p>A common criticism is that the prior is not objective. While the choice of prior can be subjective, it must be explicitly stated, making all assumptions transparent. This allows for an objective comparison of the different approaches.</p><p>In fact, there are two common types of priors in least squares fitting.</p><ol><li><p><span>$p_0(\lambda\mid \{x_i\}_{i=1}^N, m) = 1$</span>, i.e. a uniform prior. Since one usually uses a computer, there is a largest number <span>$b &lt;\infty$</span> and a smallest number <span>$a &gt; -\infty$</span> that the computer can use. Then one may choose the uniform distribution <span>$p_0(\lambda \mid \{x_i\}_{i=1}^N, m) = \frac{1}{b-a}$</span>. Sine the posterior probability is only considered up to proportionality, one can simply use <span>$p_0(\lambda\mid \{x_i\}_{i=1}^N, m) = 1$</span>. This leads to a <strong>maximum likelihood</strong> objective.</p></li><li><p>In ill-defined problems, it is common practice to use some kind of regularization. In some cases, these regularizations correspond to certain priors. For example, the <a href="https://en.wikipedia.org/wiki/Ridge_regression">Tikhonov regularization</a> essentially uses the prior <span>$p_0(\lambda\mid \{x_i\}_{i=1}^N, m) \propto \exp(-||\Gamma \lambda ||^2)$</span>.</p></li></ol></div></div><h2 id="Independent-data-points"><a class="docs-heading-anchor" href="#Independent-data-points">Independent data points</a><a id="Independent-data-points-1"></a><a class="docs-heading-anchor-permalink" href="#Independent-data-points" title="Permalink"></a></h2><p>A common assumption is that the data points are independent. While this is not a necessity, writing general likelihood functions is usually not trivial. If the data points are independent, the likelihood function becomes a product of likelihood functions for the individual data point likelihoods:</p><p class="math-container">\[\ell(\{y_i\}_{i=1}^N \mid \lambda, \{x_i\}_{i=1}^N m ) = \prod_{i=1}^N \ell_i(y_i\mid \lambda, x_i, m)\]</p><p>Note that the likelihoods can differ for the different data points, here denoted by <span>$\ell_i$</span>.  Thus the posterior distribution becomes</p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) \propto  p_0(\lambda\mid \{x_i\}_{i=1}^N, m) \prod_{i=1}^n \ell_i(y_i\mid \lambda, x_i,m)\]</p><p>In general, the independent variable <span>$x_i$</span> is a measured quantity, where the true value <span>$\mathcal{X}_i$</span> is unknown. If the density function <span>$p_i(\mathcal{X}_i\mid \lambda, x_i, m)$</span> of true values <span>$\mathcal{X}_i$</span> is known, marginalization can be used to express the likelihood</p><p class="math-container">\[\ell_i(y_i\mid \lambda, x_i, m) = \int \ell_i(y_i \mid \mathcal{X}_i, \lambda, x_i, m)\cdot p_I(\mathcal{X}_i\mid \lambda, x_i,m) \ d\mathcal{X}_i\]</p><p>The likelihood <span>$\ell_i(y_i\mid \mathcal{X}_i, \lambda, x_i, m)$</span> is essentially given by the probability density function <span>$q_i(y_i\mid \mathcal{Y}_i)$</span> to measure the value <span>$y_i$</span> when the true value is <span>$\mathcal{Y}_i$</span>. Since <span>$\mathcal{Y}_i = m(\mathcal{X}_i,\lambda)$</span> by assumption of the model it follows that</p><p class="math-container">\[\ell_i(y_i \mid \mathcal{X}_i, \lambda, x_i, m) = q_i(y_i\mid m(\mathcal{X}_i, \lambda))\]</p><h2 id="No-x-uncertainty"><a class="docs-heading-anchor" href="#No-x-uncertainty">No <span>$x$</span>-uncertainty</a><a id="No-x-uncertainty-1"></a><a class="docs-heading-anchor-permalink" href="#No-x-uncertainty" title="Permalink"></a></h2><p>A convenient situation is, when the distinction between <span>$x_i$</span> and <span>$\mathcal{X}_i$</span> can be neglected, e.g. because the independent variable can be measured with high precision. Then <span>$p_i(\mathcal{X}_i\mid \lambda, x_i, m)$</span> becomes a Dirac distribution, and</p><p class="math-container">\[\ell_i(y_i\mid \lambda, x_i, m) = q_i(y_i\mid m(x_i,\lambda))\]</p><p>Hence, the posterior distribution reads </p><p class="math-container">\[p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) \propto  p_0(\lambda\mid \{x_i\}_{i=1}^N, m) \prod_{i=1}^n q_i(y_i\mid m(x_i,\lambda))\]</p><div class="admonition is-success"><header class="admonition-header">Implementing x-uncertainties</header><div class="admonition-body"><p>In most examples of this documentation, it is assumed that there is no <span>$x$</span>-uncertainty, as it is often impossible to solve the <span>$x$</span>-uncertainty integral. Hence, the likelihoods <span>$\ell_i$</span> for the individual data points are simply referred to as <span>$y$</span>-uncertainty distributions <span>$q_i$</span>, in most parts of the documentation. However, if the <span>$x$</span>-uncertainty integral can be solved analytically or can be approximated efficiently, the likelihoods <span>$\ell_i$</span> can be used instead of the <span>$y$</span>-uncertainty distributions <span>$q_i$</span>.</p></div></div><h2 id="Retrieving-the-LSQ-objective"><a class="docs-heading-anchor" href="#Retrieving-the-LSQ-objective">Retrieving the LSQ objective</a><a id="Retrieving-the-LSQ-objective-1"></a><a class="docs-heading-anchor-permalink" href="#Retrieving-the-LSQ-objective" title="Permalink"></a></h2><p>Using the aforementioned uniform prior <span>$p_0(\lambda\mid \{x_i\}_{i=1}^N, m) = 1$</span> and assuming normal distributions for the <span>$q_i$</span> with standard deviations <span>$\Delta y_i$</span> leads to</p><p class="math-container">\[\begin{aligned}
p(\lambda \mid \{x_i\}_{i=1}^N, \{y_i\}_{i=1}^N, m) &amp;\propto   \prod_{i=1}^n \frac{1}{\sqrt{2\pi}\Delta y_i}\exp\left(- \frac{(y_i - m(x_i,\lambda))^2}{2\Delta y_i^2}\right) \\ 
&amp;\propto \prod_{i=1}^n \exp\left(- \frac{(y_i - m(x_i,\lambda))^2}{2\Delta y_i^2}\right)\\ 
&amp; \quad = \exp\left(- \sum_{i=1}^N \frac{(y_i - m(x_i,\lambda))^2}{2\Delta y_i^2}\right)
\end{aligned}\]</p><p>Maximizing this function is equivalent to minimizing</p><p class="math-container">\[\sum_{i=1}^N \frac{(y_i - m(x_i,\lambda))^2}{2\Delta y_i^2}\]</p><p>which is the weighted least squares objective, up to a factor <span>$\frac{1}{2}$</span> (see <a href="../lsq_background/#Background:-LSQ">Background: LSQ</a>).</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../lsq_implementation/">« How to implement</a><a class="docs-footer-nextpage" href="../posterior_implementation/">How to implement »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Thursday 12 September 2024 16:37">Thursday 12 September 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
